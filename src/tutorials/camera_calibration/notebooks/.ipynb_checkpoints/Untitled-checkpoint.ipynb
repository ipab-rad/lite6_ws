{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445d5ccf",
   "metadata": {},
   "source": [
    "# Set up MoveIt for Planning Robot Poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a543f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# generic ros libraries\n",
    "import rclpy\n",
    "from rclpy.logging import get_logger\n",
    "\n",
    "# moveit python library\n",
    "from moveit.core.robot_state import RobotState\n",
    "from moveit.planning import (\n",
    "    MoveItPy,\n",
    "    MultiPipelinePlanRequestParameters,\n",
    ")\n",
    "\n",
    "from ament_index_python.packages import get_package_share_directory\n",
    "from moveit_configs_utils import MoveItConfigsBuilder\n",
    "\n",
    "def plan_and_execute(\n",
    "    robot,\n",
    "    planning_component,\n",
    "    logger,\n",
    "    single_plan_parameters=None,\n",
    "    multi_plan_parameters=None,\n",
    "    sleep_time=0.0,\n",
    "):\n",
    "    \"\"\"Helper function to plan and execute a motion.\"\"\"\n",
    "    # plan to goal\n",
    "    logger.info(\"Planning trajectory\")\n",
    "    if multi_plan_parameters is not None:\n",
    "        plan_result = planning_component.plan(\n",
    "            multi_plan_parameters=multi_plan_parameters\n",
    "        )\n",
    "    elif single_plan_parameters is not None:\n",
    "        plan_result = planning_component.plan(\n",
    "            single_plan_parameters=single_plan_parameters\n",
    "        )\n",
    "    else:\n",
    "        plan_result = planning_component.plan()\n",
    "\n",
    "    # execute the plan\n",
    "    if plan_result:\n",
    "        logger.info(\"Executing plan\")\n",
    "        robot_trajectory = plan_result.trajectory\n",
    "        robot.execute(robot_trajectory, controllers=[])\n",
    "    else:\n",
    "        logger.error(\"Planning failed\")\n",
    "\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "# we need to specify our moveit_py config at the top of each notebook we use. \n",
    "# this is since we will start spinning a moveit_py node within this notebook.\n",
    "\n",
    "moveit_config = (\n",
    "        MoveItConfigsBuilder(robot_name=\"lite6\", package_name=\"moveit_resources_lite6_moveit_config\")\n",
    "        .robot_description_semantic(file_path=\"config/lite6.srdf\")\n",
    "        .trajectory_execution(file_path=\"config/moveit_controllers.yaml\")\n",
    "        .robot_description(file_path=get_package_share_directory(\"moveit_resources_lite6_description\")\n",
    "                          + \"/urdf/lite6.urdf\")\n",
    "        .moveit_cpp(\n",
    "            file_path=get_package_share_directory(\"lite6_motion_planning_demos\")\n",
    "            + \"/config/moveit_cpp.yaml\"\n",
    "        )\n",
    "        .to_moveit_configs()\n",
    "    ).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28698c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1699029217.740555583] [moveit_cpp_initializer]: Initialize rclcpp\n",
      "[INFO] [1699029217.741181345] [moveit_cpp_initializer]: Initialize node parameters\n",
      "[INFO] [1699029217.741198425] [moveit_cpp_initializer]: Initialize node and executor\n",
      "[INFO] [1699029217.761422174] [moveit_cpp_initializer]: Spin separate thread\n",
      "[INFO] [1699029217.766137128] [moveit_3546831652.rdf_loader]: Loaded robot model in 0.00211891 seconds\n",
      "[INFO] [1699029217.766218999] [moveit_robot_model.robot_model]: Loading robot model 'UF_ROBOT'...\n",
      "[INFO] [1699029217.766233239] [moveit_robot_model.robot_model]: No root/virtual joint specified in SRDF. Assuming fixed joint\n",
      "[INFO] [1699029217.803400799] [moveit_kinematics_base.kinematics_base]: Joint weights for group 'lite6': 1 1 1 1 1 1\n",
      "[INFO] [1699029218.197454652] [moveit_3546831652.planning_scene_monitor]: Publishing maintained planning scene on 'monitored_planning_scene'\n",
      "[INFO] [1699029218.197607822] [moveit_3546831652.moveit_cpp]: Listening to '/joint_states' for joint states\n",
      "[INFO] [1699029218.198050774] [moveit_3546831652.current_state_monitor]: Listening to joint states on topic '/joint_states'\n",
      "[INFO] [1699029218.198384665] [moveit_3546831652.planning_scene_monitor]: Listening to '/moveit_cpp/planning_scene_monitor' for attached collision objects\n",
      "[INFO] [1699029218.198397165] [moveit_3546831652.planning_scene_monitor]: Starting planning scene monitor\n",
      "[INFO] [1699029218.198849026] [moveit_3546831652.planning_scene_monitor]: Listening to '/moveit_cpp/publish_planning_scene'\n",
      "[INFO] [1699029218.198861226] [moveit_3546831652.planning_scene_monitor]: Starting world geometry update monitor for collision objects, attached objects, octomap updates.\n",
      "[INFO] [1699029218.199138307] [moveit_3546831652.planning_scene_monitor]: Listening to 'collision_object'\n",
      "[INFO] [1699029218.199421028] [moveit_3546831652.planning_scene_monitor]: Listening to 'planning_scene_world' for planning scene world geometry\n",
      "[WARN] [1699029218.200451411] [moveit_3546831652.occupancy_map_monitor]: Resolution not specified for Octomap. Assuming resolution = 0.1 instead\n",
      "[ERROR] [1699029218.200466991] [moveit_3546831652.occupancy_map_monitor]: No 3D sensor plugin(s) defined for octomap updates\n",
      "[INFO] [1699029218.235967105] [moveit_3546831652.planning_pipeline]: Using planning interface 'OMPL'\n",
      "[INFO] [1699029218.241918154] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Add Time Optimal Parameterization'\n",
      "[INFO] [1699029218.241934014] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Resolve constraint frames to robot links'\n",
      "[INFO] [1699029218.241939154] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Workspace Bounds'\n",
      "[INFO] [1699029218.241943584] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Start State Bounds'\n",
      "[INFO] [1699029218.241947354] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Start State In Collision'\n",
      "[INFO] [1699029218.241951734] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Start State Path Constraints'\n",
      "[INFO] [1699029218.248534054] [moveit.pilz_industrial_motion_planner.joint_limits_aggregator]: Reading limits from namespace robot_description_planning\n",
      "[INFO] [1699029218.254843392] [moveit.pilz_industrial_motion_planner]: Available plugins: pilz_industrial_motion_planner/PlanningContextLoaderCIRC pilz_industrial_motion_planner/PlanningContextLoaderLIN pilz_industrial_motion_planner/PlanningContextLoaderPTP \n",
      "[INFO] [1699029218.254851022] [moveit.pilz_industrial_motion_planner]: About to load: pilz_industrial_motion_planner/PlanningContextLoaderCIRC\n",
      "[INFO] [1699029218.256276176] [moveit.pilz_industrial_motion_planner]: Registered Algorithm [CIRC]\n",
      "[INFO] [1699029218.256289546] [moveit.pilz_industrial_motion_planner]: About to load: pilz_industrial_motion_planner/PlanningContextLoaderLIN\n",
      "[INFO] [1699029218.257173499] [moveit.pilz_industrial_motion_planner]: Registered Algorithm [LIN]\n",
      "[INFO] [1699029218.257181099] [moveit.pilz_industrial_motion_planner]: About to load: pilz_industrial_motion_planner/PlanningContextLoaderPTP\n",
      "[INFO] [1699029218.258029501] [moveit.pilz_industrial_motion_planner]: Registered Algorithm [PTP]\n",
      "[INFO] [1699029218.258038771] [moveit_3546831652.planning_pipeline]: Using planning interface 'Pilz Industrial Motion Planner'\n",
      "[INFO] [1699029218.262862786] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Workspace Bounds'\n",
      "[INFO] [1699029218.262877316] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Start State Bounds'\n",
      "[INFO] [1699029218.262882406] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Start State In Collision'\n",
      "[INFO] [1699029218.262886476] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Start State Path Constraints'\n",
      "[INFO] [1699029218.270908729] [moveit_3546831652.planning_pipeline]: Using planning interface 'CHOMP'\n",
      "[INFO] [1699029218.275699753] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Add Time Optimal Parameterization'\n",
      "[INFO] [1699029218.275713343] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Workspace Bounds'\n",
      "[INFO] [1699029218.275718373] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Start State Bounds'\n",
      "[INFO] [1699029218.275722383] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Start State In Collision'\n",
      "[INFO] [1699029218.275726223] [moveit_3546831652.planning_pipeline]: Using planning request adapter 'Fix Start State Path Constraints'\n",
      "[INFO] [1699029218.301940620] [moveit.plugins.moveit_simple_controller_manager]: Added FollowJointTrajectory controller for lite6_traj_controller\n",
      "[INFO] [1699029218.302124841] [moveit.plugins.moveit_simple_controller_manager]: Returned 1 controllers in list\n",
      "[INFO] [1699029218.302169341] [moveit.plugins.moveit_simple_controller_manager]: Returned 1 controllers in list\n",
      "[INFO] [1699029218.302515482] [moveit_3546831652.trajectory_execution_manager]: Trajectory execution is managing controllers\n",
      "[INFO] [1699029218.349095640] [moveit_py.pose_goal]: MoveItPy instance created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rclpy.init()\n",
    "logger = get_logger(\"moveit_py.pose_goal\")\n",
    "    \n",
    "# instantiate MoveItPy instance and get planning component\n",
    "lite6 = MoveItPy(node_name=\"moveit_py\", config_dict=moveit_config)\n",
    "lite6_arm = lite6.get_planning_component(\"lite6\")\n",
    "logger.info(\"MoveItPy instance created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226c87c",
   "metadata": {},
   "source": [
    "# Calibration Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548e6dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1699030664.120907505] [rcl.logging_rosout]: Publisher already registered for node name: 'calibration_node'. If this is due to multiple nodes with the same name then all logs for the logger named 'calibration_node' will go out over the existing publisher. As soon as any node with that name is destructed it will unregister the publisher, preventing any further logs for that name from being published on the rosout topic.\n"
     ]
    }
   ],
   "source": [
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import JointState\n",
    "from sensor_msgs.msg import Image\n",
    "\n",
    "\n",
    "class Calibration(Node):\n",
    "    \"\"\"An abstract base class for deploying learnt policies.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialise the policy.\"\"\"\n",
    "        super().__init__(\"calibration_node\")\n",
    "        self.logger = self.get_logger()\n",
    "\n",
    "        # subscribe to joint state topic\n",
    "        self.subscription = self.create_subscription(\n",
    "            Image,\n",
    "            '/zed2i/zed_node/rgb/image_rect_color',\n",
    "            self.dummy_callback,\n",
    "            10)\n",
    "        \n",
    "        # stores the most recent image observation\n",
    "        self._last_image = None\n",
    "        \n",
    "    def dummy_callback(self, sensor_msg):\n",
    "        self.image = sensor_msg\n",
    "\n",
    "node = Calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccbd3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "rclpy.spin_once(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc371bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from message_filters import Subscriber\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2273937",
   "metadata": {},
   "source": [
    "# Collect Calibration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera image\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pyzed.sl as sl\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from geometry_msgs.msg import PoseStamped\n",
    "\n",
    "\n",
    "# setup camera\n",
    "zed = sl.Camera()\n",
    "init_params = sl.InitParameters()\n",
    "zed.open(init_params)\n",
    "\n",
    "def base2robot():\n",
    "    lite6_arm.set_start_state_to_current_state()\n",
    "    robot_state = lite6_arm.get_start_state()\n",
    "    t_mat = robot_state.get_frame_transform(\"link6\")\n",
    "    return t_mat[:3, :-1], t_mat[:3, -1]\n",
    "\n",
    "def eef_pose():\n",
    "    lite6_arm.set_start_state_to_current_state()\n",
    "    robot_state = lite6_arm.get_start_state()\n",
    "    return robot_state.get_pose(\"link6\")\n",
    "\n",
    "def capture_image():\n",
    "    if (zed.grab() == sl.ERROR_CODE.SUCCESS) :\n",
    "        image = sl.Mat()\n",
    "        zed.retrieve_image(image, sl.VIEW.LEFT) # Get the left image\n",
    "        print(\"Image resolution: \", image.get_width(), \" x \", image.get_height())\n",
    "        return image\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def plan_and_execute(\n",
    "    robot,\n",
    "    planning_component,\n",
    "    single_plan_parameters=None,\n",
    "    multi_plan_parameters=None,\n",
    "    sleep_time=0.0,\n",
    "):\n",
    "    \"\"\"Helper function to plan and execute a motion.\"\"\"\n",
    "    # plan to goal\n",
    "    if multi_plan_parameters is not None:\n",
    "        plan_result = planning_component.plan(\n",
    "            multi_plan_parameters=multi_plan_parameters\n",
    "        )\n",
    "    elif single_plan_parameters is not None:\n",
    "        plan_result = planning_component.plan(\n",
    "            single_plan_parameters=single_plan_parameters\n",
    "        )\n",
    "    else:\n",
    "        plan_result = planning_component.plan()\n",
    "\n",
    "    # execute the plan\n",
    "    if plan_result:\n",
    "        robot_trajectory = plan_result.trajectory\n",
    "        #input(\"Press Enter to execute trajectory\")\n",
    "        robot.execute(robot_trajectory, controllers=[])\n",
    "            \n",
    "    \n",
    "def move_2_random_pose():\n",
    "    # set plan start state to current state\n",
    "    lite6_arm.set_start_state_to_current_state()\n",
    "    \n",
    "    # random pose within workspace\n",
    "    pose_goal = PoseStamped()\n",
    "    pose_goal.header.frame_id = \"link_base\"\n",
    "    pose_goal.pose.position.x = np.random.uniform(0.3, 0.4)\n",
    "    pose_goal.pose.position.y = np.random.uniform(-0.1, 0.1)\n",
    "    pose_goal.pose.position.z = np.random.uniform(0.2, 0.4)\n",
    "    \n",
    "\n",
    "    # Create a rotation object from Euler angles specifying axes of rotation\n",
    "    #rot_x = np.random.uniform()\n",
    "    #rot_y = np.random.uniform()\n",
    "    #rot_z = np.random.uniform()\n",
    "    #rot = Rotation.from_euler('xyz', [, , ], degrees=True)\n",
    "    # Convert to quaternions and print\n",
    "    #rot_quat = rot.as_quat()\n",
    "\n",
    "    pose_goal.pose.orientation.x = 0.55\n",
    "    pose_goal.pose.orientation.y = 0.0\n",
    "    pose_goal.pose.orientation.z =0.82\n",
    "    pose_goal.pose.orientation.w =0.115\n",
    "    \n",
    "    \n",
    "    # get current pose\n",
    "    lite6_arm.set_goal_state(pose_stamped_msg=pose_goal, pose_link=\"link6\")\n",
    "    \n",
    "    plan_and_execute(lite6, lite6_arm, sleep_time=3.0)\n",
    "    \n",
    "    \n",
    "def data_capture():    \n",
    "    # data structures to store samples\n",
    "    images = []\n",
    "    base2robot_transforms = [] #TODO: fix\n",
    "    \n",
    "    for _ in range(15):\n",
    "        time.sleep(5.0)\n",
    "        img = capture_image()\n",
    "        base2robot_sample = base2robot()\n",
    "        \n",
    "        images.append(img)\n",
    "        base2robot_transforms.append(base2robot_sample)\n",
    "        \n",
    "        move_2_random_pose()\n",
    "        \n",
    "    return images, base2robot_transforms\n",
    "        \n",
    "        \n",
    "def detect_aruco(images):\n",
    "    # set up parameters\n",
    "    ARUCO_DICT = aruco.Dictionary_get(aruco.DICT_5X5_100)\n",
    "    CHARUCO_BOARD = aruco.CharucoBoard_create(\n",
    "        squaresX=14,\n",
    "        squaresY=9,\n",
    "        squareLength=0.02,\n",
    "        markerLength=0.015,\n",
    "        dictionary=ARUCO_DICT,\n",
    "    )\n",
    "    detector_params = cv2.aruco.DetectorParameters_create()\n",
    "    detector_params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    \n",
    "    for image in images:\n",
    "        cv_image = cv2.cvtColor(image.numpy(), cv2.COLOR_BGRA2GRAY)\n",
    "        img_size = cv_image.shape[:2]\n",
    "        \n",
    "        corners, ids, rejected = cv2.aruco.detectMarkers(cv_image, ARUCO_DICT, parameters=detector_params)\n",
    "\n",
    "        corners, ids, _, _ = cv2.aruco.refineDetectedMarkers(\n",
    "                    cv_image,\n",
    "                    CHARUCO_BOARD,\n",
    "                    corners,\n",
    "                    ids,\n",
    "                    rejected,\n",
    "                    parameters=detector_params,\n",
    "                    # TODO: add camera intrinsic parameters\n",
    "            )\n",
    "\n",
    "        num_corners_found, charuco_corners, charuco_ids = aruco.interpolateCornersCharuco(\n",
    "            markerCorners=corners, markerIds=ids, image=cv_image, board=CHARUCO_BOARD, # TODO: add camera intrinsic parameters\n",
    "        )\n",
    "\n",
    "        readings = []\n",
    "        readings.append((corners, charuco_corners, charuco_ids, img_size))\n",
    "    \n",
    "    return readings\n",
    "        \n",
    "def target2cam(readings):\n",
    "    init_corners_all = []  # Corners discovered in all images processed\n",
    "    init_ids_all = []  # Aruco ids corresponding to corners discovered\n",
    "    fixed_image_size = readings[0][3]\n",
    "\n",
    "    # Proccess Readings #\n",
    "    init_successes = []\n",
    "    for i in range(len(readings)):\n",
    "        corners, charuco_corners, charuco_ids, img_size = readings[i]\n",
    "        assert img_size == fixed_image_size\n",
    "        init_corners_all.append(charuco_corners)\n",
    "        init_ids_all.append(charuco_ids)\n",
    "        init_successes.append(i)\n",
    "\n",
    "    # First Pass: Find Outliers #\n",
    "    threshold = self.num_img_threshold\n",
    "    if len(init_successes) < threshold:\n",
    "        return None\n",
    "    # print('Not enough points round 1')\n",
    "    # print('Num Points: ', len(init_successes))\n",
    "    # return None\n",
    "\n",
    "    calibration_error, cameraMatrix, distCoeffs, rvecs, tvecs, stdIntrinsics, stdExtrinsics, perViewErrors = (\n",
    "        aruco.calibrateCameraCharucoExtended(\n",
    "            charucoCorners=init_corners_all,\n",
    "            charucoIds=init_ids_all,\n",
    "            board=CHARUCO_BOARD,\n",
    "            imageSize=fixed_image_size,\n",
    "            flags=calib_flags,\n",
    "            **self._intrinsics_dict[self._curr_cam_id],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Remove Outliers #\n",
    "    threshold = self.num_img_threshold if train else 5\n",
    "    final_corners_all = [\n",
    "        init_corners_all[i] for i in range(len(perViewErrors)) if perViewErrors[i] <= self.inlier_error_threshold\n",
    "    ]\n",
    "    final_ids_all = [\n",
    "        init_ids_all[i] for i in range(len(perViewErrors)) if perViewErrors[i] <= self.inlier_error_threshold\n",
    "    ]\n",
    "    final_successes = [\n",
    "        init_successes[i] for i in range(len(perViewErrors)) if perViewErrors[i] <= self.inlier_error_threshold\n",
    "    ]\n",
    "    if len(final_successes) < threshold:\n",
    "        return None\n",
    "    # print('Not enough points round 2')\n",
    "    # print('Num Points: ', len(final_successes))\n",
    "    # print('Error Mean: ', perViewErrors.mean())\n",
    "    # print('Error Std: ', perViewErrors.std())\n",
    "    # return None\n",
    "\n",
    "    # Second Pass: Calculate Finalized Extrinsics #\n",
    "    calibration_error, cameraMatrix, distCoeffs, rvecs, tvecs = aruco.calibrateCameraCharuco(\n",
    "        charucoCorners=final_corners_all,\n",
    "        charucoIds=final_ids_all,\n",
    "        board=CHARUCO_BOARD,\n",
    "        imageSize=fixed_image_size,\n",
    "        flags=calib_flags,\n",
    "        **self._intrinsics_dict[self._curr_cam_id],\n",
    "    )\n",
    "\n",
    "    # Return Transformation #\n",
    "    if calibration_error > self.reprojection_error_threshold:\n",
    "        return None\n",
    "    # print('Failed Calibration Threshold')\n",
    "    # print('Calibration Error: ', calibration_error)\n",
    "    # return None\n",
    "\n",
    "    rmats = [R.from_rotvec(rvec.flatten()).as_matrix() for rvec in rvecs]\n",
    "    tvecs = [tvec.flatten() for tvec in tvecs]\n",
    "\n",
    "    return rmats, tvecs, final_successes\n",
    "    \n",
    "# from PIL import Image    \n",
    "# data = image.numpy()\n",
    "\n",
    "# # Convert the NumPy array to a Pillow image\n",
    "# image = Image.fromarray(data)\n",
    "\n",
    "# # Display the image\n",
    "# image.show()\n",
    "\n",
    "#move_random_pose()\n",
    "\n",
    "images, base2robot_transforms = data_capture()\n",
    "\n",
    "\n",
    "print(images)\n",
    "\n",
    "# import numpy as np\n",
    "# image = np.copy(cv_image)\n",
    "# image = aruco.drawDetectedMarkers(image=image, corners=corners)\n",
    "# cv2.imshow(\"test\", image)\n",
    "# cv2.waitKey(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "readings = detect_aruco(images)\n",
    "\n",
    "def target2cam(readings):\n",
    "    # set up parameters\n",
    "    ARUCO_DICT = aruco.Dictionary_get(aruco.DICT_5X5_100)\n",
    "    CHARUCO_BOARD = aruco.CharucoBoard_create(\n",
    "        squaresX=14,\n",
    "        squaresY=9,\n",
    "        squareLength=0.02,\n",
    "        markerLength=0.015,\n",
    "        dictionary=ARUCO_DICT,\n",
    "    )\n",
    "    detector_params = cv2.aruco.DetectorParameters_create()\n",
    "    detector_params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    calib_flags = cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_FIX_PRINCIPAL_POINT + cv2.CALIB_FIX_FOCAL_LENGTH\n",
    "\n",
    "    \n",
    "    init_corners_all = []  # Corners discovered in all images processed\n",
    "    init_ids_all = []  # Aruco ids corresponding to corners discovered\n",
    "    fixed_image_size = readings[0][3]\n",
    "\n",
    "    # Proccess Readings #\n",
    "    init_successes = []\n",
    "    for i in range(len(readings)):\n",
    "        corners, charuco_corners, charuco_ids, img_size = readings[i]\n",
    "        assert img_size == fixed_image_size\n",
    "        init_corners_all.append(charuco_corners)\n",
    "        init_ids_all.append(charuco_ids)\n",
    "        init_successes.append(i)\n",
    "\n",
    "    # First Pass: Find Outliers #\n",
    "    threshold = 1\n",
    "    if len(init_successes) < threshold:\n",
    "        return None\n",
    "    # print('Not enough points round 1')\n",
    "    # print('Num Points: ', len(init_successes))\n",
    "    # return None\n",
    "\n",
    "    calibration_error, cameraMatrix, distCoeffs, rvecs, tvecs, stdIntrinsics, stdExtrinsics, perViewErrors = (\n",
    "        aruco.calibrateCameraCharucoExtended(\n",
    "            charucoCorners=init_corners_all,\n",
    "            charucoIds=init_ids_all,\n",
    "            board=CHARUCO_BOARD,\n",
    "            imageSize=fixed_image_size,\n",
    "            flags=calib_flags,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Remove Outliers #\n",
    "    threshold = self.num_img_threshold\n",
    "    final_corners_all = [\n",
    "        init_corners_all[i] for i in range(len(perViewErrors)) if perViewErrors[i] <= self.inlier_error_threshold\n",
    "    ]\n",
    "    final_ids_all = [\n",
    "        init_ids_all[i] for i in range(len(perViewErrors)) if perViewErrors[i] <= self.inlier_error_threshold\n",
    "    ]\n",
    "    final_successes = [\n",
    "        init_successes[i] for i in range(len(perViewErrors)) if perViewErrors[i] <= self.inlier_error_threshold\n",
    "    ]\n",
    "    if len(final_successes) < threshold:\n",
    "        return None\n",
    "    # print('Not enough points round 2')\n",
    "    # print('Num Points: ', len(final_successes))\n",
    "    # print('Error Mean: ', perViewErrors.mean())\n",
    "    # print('Error Std: ', perViewErrors.std())\n",
    "    # return None\n",
    "\n",
    "    # Second Pass: Calculate Finalized Extrinsics #\n",
    "    calibration_error, cameraMatrix, distCoeffs, rvecs, tvecs = aruco.calibrateCameraCharuco(\n",
    "        charucoCorners=final_corners_all,\n",
    "        charucoIds=final_ids_all,\n",
    "        board=CHARUCO_BOARD,\n",
    "        imageSize=fixed_image_size,\n",
    "        flags=calib_flags,\n",
    "    )\n",
    "\n",
    "    # Return Transformation #\n",
    "    if calibration_error > self.reprojection_error_threshold:\n",
    "        return None\n",
    "    # print('Failed Calibration Threshold')\n",
    "    # print('Calibration Error: ', calibration_error)\n",
    "    # return None\n",
    "\n",
    "    rmats = [R.from_rotvec(rvec.flatten()).as_matrix() for rvec in rvecs]\n",
    "    tvecs = [tvec.flatten() for tvec in tvecs]\n",
    "\n",
    "    return rmats, tvecs, final_successes\n",
    "\n",
    "target2cam(readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b476b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].numpy().shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171297a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "readings[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base2robot\n",
    "\n",
    "\n",
    "\n",
    "print(base2robot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73dd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7b43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import aruco\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_9X14_25)\n",
    "# arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "# (corners, ids, rejected) = cv2.aruco.detectMarkers(image, arucoDict,\n",
    "# \tparameters=arucoParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e32db43",
   "metadata": {},
   "source": [
    "# Run Calibration Optmization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ab724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef653ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
